# dataset_parser_service.py - æ•°æ®é›†è§£ææœåŠ¡

# ğŸ“Š æ•°æ®é›†è§£ææœåŠ¡ - ä¸“é—¨å¤„ç†LevelXç­‰æ•°æ®é›†çš„è§£æ
import logging
from typing import Dict, Any, List, Tuple
from collections import defaultdict

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥tactics2d
try:
    from tactics2d.dataset_parser import LevelXParser
    TACTICS2D_AVAILABLE = True
    logger.info("âœ… Tactics2Dåº“å·²æˆåŠŸå¯¼å…¥")
except ImportError:
    TACTICS2D_AVAILABLE = False
    logger.warning("âš ï¸ Tactics2Dåº“æœªæ‰¾åˆ°ï¼Œéƒ¨åˆ†åŠŸèƒ½å°†ä¸å¯ç”¨")

class DatasetParserService:
    """
    å°è£…äº†ä¸tactics2dåº“çš„äº¤äº’ï¼Œå¹¶æä¾›äº†å°†æ•°æ®è½¬æ¢ä¸º
    å‰ç«¯æ¸²æŸ“æ‰€éœ€æ ¼å¼çš„æ ¸å¿ƒåŠŸèƒ½ã€‚
    """

    def is_available(self) -> bool:
        """æ£€æŸ¥tactics2dåº“æ˜¯å¦æˆåŠŸå¯¼å…¥"""
        return TACTICS2D_AVAILABLE

    def _restructure_for_streaming(self, participants: Dict[int, Any], frame_step: int, actual_stamp_range: Tuple[int, int] = None) -> Dict[int, List[Dict]]:
        """
        å°†tactics2dè¿”å›çš„ "ä»¥å‚ä¸è€…ä¸ºä¸­å¿ƒ" çš„æ•°æ®é‡æ„ä¸º "ä»¥å¸§ä¸ºä¸­å¿ƒ" çš„æ•°æ®ã€‚
        è¿™æ˜¯å°†æ•°æ®é€‚é…åˆ°å‰ç«¯æ¸²æŸ“çš„å…³é”®æ­¥éª¤ã€‚

        Args:
            participants: tactics2dçš„parse_trajectoryè¿”å›çš„åŸå§‹å‚ä¸è€…å­—å…¸ã€‚
            frame_step: æ•°æ®å¤„ç†çš„å¸§é—´éš”æ­¥é•¿ã€‚
            actual_stamp_range: å®é™…çš„æ—¶é—´æˆ³èŒƒå›´ï¼ˆæ¥è‡ªparse_trajectoryè¿”å›å€¼ï¼‰

        Returns:
            ä¸€ä¸ªä»¥å¸§å·ä¸ºé”®ï¼Œå€¼ä¸ºè¯¥å¸§æ‰€æœ‰è½¦è¾†çŠ¶æ€åˆ—è¡¨çš„å­—å…¸ã€‚
        """
        frames = defaultdict(list)
        if not participants:
            return {}

        logger.info(f"ğŸ”„ å¼€å§‹é‡æ„æ•°æ®ç»“æ„ï¼Œå…± {len(participants)} ä¸ªå‚ä¸è€…...")
        
        # æ·»åŠ ä¸€ä¸ªæ ‡å¿—ï¼Œç¡®ä¿æˆ‘ä»¬åªæ‰“å°ä¸€æ¬¡è°ƒè¯•ä¿¡æ¯
        debug_info_printed = False

        # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œä½¿ç”¨å…¨å±€æ—¶é—´èŒƒå›´æ¥è¿­ä»£ï¼Œè€Œä¸æ˜¯å•ä¸ªè½¨è¿¹çš„æ—¶é—´èŒƒå›´
        if not actual_stamp_range:
            logger.error("âŒ ç¼ºå°‘å®é™…æ—¶é—´æˆ³èŒƒå›´ï¼Œæ— æ³•é‡æ„æ•°æ®")
            return {}
            
        start_time, end_time = actual_stamp_range
        logger.info(f"ğŸ• ä½¿ç”¨æ—¶é—´èŒƒå›´: {start_time}ms åˆ° {end_time}ms")
        
        # æŒ‰æ—¶é—´é—´éš”é‡‡æ ·ï¼ˆæ¯40msï¼Œå¯¹åº”25Hzï¼‰
        time_step = 40  # æ¯«ç§’
        processed_count = 0
        
        for timestamp in range(int(start_time), int(end_time), time_step):
            frame_participants = []
            
            for p_id, p_obj in participants.items():
                # --- è°ƒè¯•æ—¥å¿—ï¼ˆåªæ‰“å°ä¸€æ¬¡ï¼‰---
                if not debug_info_printed:
                    logger.info("=================================================")
                    logger.info(f"ğŸ” DEBUG: Inspecting Participant object structure for participant ID: {p_id}")
                    logger.info(f"   - Object Type: {type(p_obj)}")
                    logger.info(f"   - Object Representation: {p_obj}")
                    logger.info(f"   - Object Attributes (using dir()): {dir(p_obj)}")
                    if hasattr(p_obj, '__dict__'):
                        logger.info(f"   - Object __dict__: {p_obj.__dict__}")
                    if hasattr(p_obj, 'trajectory'):
                        logger.info(f"   - Trajectory Type: {type(p_obj.trajectory)}")
                        logger.info(f"   - Trajectory Attributes: {dir(p_obj.trajectory)}")
                    logger.info("=================================================")
                    debug_info_printed = True
                # --- ç»“æŸè°ƒè¯• ---
                
                # æ£€æŸ¥å‚ä¸è€…åœ¨æ­¤æ—¶é—´æˆ³æ˜¯å¦æ´»è·ƒ
                try:
                    if not hasattr(p_obj, 'is_active'):
                        logger.warning(f"âš ï¸ å‚ä¸è€… {p_id} ç¼ºå°‘ is_active æ–¹æ³•")
                        continue
                        
                    if not p_obj.is_active(timestamp):
                        continue
                    
                    # å°è¯•è·å–ç‰¹å®šæ—¶é—´æˆ³çš„çŠ¶æ€
                    state = None
                    if hasattr(p_obj, 'get_state_at_timestamp'):
                        state = p_obj.get_state_at_timestamp(timestamp)
                    elif hasattr(p_obj, 'get_state'):
                        state = p_obj.get_state(timestamp)
                    else:
                        logger.warning(f"âš ï¸ å‚ä¸è€… {p_id} ç¼ºå°‘è·å–çŠ¶æ€çš„æ–¹æ³•")
                        continue
                    
                    if state is None:
                        continue

                    frame_participants.append({
                        "id": int(p_id),
                        "x": float(getattr(state, 'x', getattr(state, 'position_x', 0.0))),
                        "y": float(getattr(state, 'y', getattr(state, 'position_y', 0.0))),
                        "vx": float(getattr(state, 'vx', getattr(state, 'velocity_x', 0.0))),
                        "vy": float(getattr(state, 'vy', getattr(state, 'velocity_y', 0.0))),
                        "heading": float(getattr(state, 'heading', getattr(state, 'orientation', 0.0)))
                    })
                    
                except Exception as participant_error:
                    logger.warning(f"âš ï¸ å¤„ç†å‚ä¸è€… {p_id} åœ¨æ—¶é—´æˆ³ {timestamp} æ—¶å‡ºé”™: {participant_error}")
                    continue
            
            # å¦‚æœè¿™ä¸€å¸§æœ‰å‚ä¸è€…ï¼Œåˆ™æ·»åŠ åˆ°ç»“æœä¸­
            if frame_participants:
                frames[timestamp] = frame_participants
                processed_count += 1
        
        if not frames:
            logger.warning("âš ï¸ æ•°æ®é‡æ„åæ²¡æœ‰ç”Ÿæˆä»»ä½•å¸§")
            return {}

        logger.info(f"âœ… æˆåŠŸå¤„ç†äº† {processed_count} ä¸ªæ—¶é—´æˆ³çš„æ•°æ®")

        # æŒ‰å¸§æ­¥é•¿è¿›è¡ŒæŠ½æ ·
        sorted_frames = sorted(frames.items())
        sampled_frames = {}
        
        # æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ–°çš„ã€ä»0å¼€å§‹çš„å¸§ç´¢å¼•
        new_frame_index = 0
        for i in range(0, len(sorted_frames), frame_step):
            original_frame_number, frame_data = sorted_frames[i]
            sampled_frames[new_frame_index] = {
                "timestamp": original_frame_number,
                "vehicles": frame_data
            }
            new_frame_index += 1

        logger.info(f"âœ… æ•°æ®é‡æ„å’ŒæŠ½æ ·å®Œæˆï¼Œä» {len(frames)} å¸§æŠ½æ ·ä¸º {len(sampled_frames)} å¸§ (æ­¥é•¿: {frame_step})")
        return sampled_frames

    def parse_dataset_for_session(
        self,
        dataset: str,
        file_id: int,
        dataset_path: str,
        frame_step: int,
        stamp_range: Tuple[int, int] = None,
        max_duration_ms: int = None
    ) -> Dict[str, Any]:
        """
        è§£ææŒ‡å®šçš„æ•°æ®é›†æ–‡ä»¶ï¼Œå¹¶ä¸ºWebSocketä¼šè¯å‡†å¤‡æ•°æ®ã€‚

        Args:
            dataset: æ•°æ®é›†ç±»å‹ (ä¾‹å¦‚, "levelx")ã€‚
            file_id: æ•°æ®é›†æ–‡ä»¶IDã€‚
            dataset_path: æ•°æ®é›†æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•ã€‚
            frame_step: å¸§é—´éš”ã€‚
            stamp_range: (å¯é€‰) æ—¶é—´æˆ³èŒƒå›´ã€‚
            max_duration_ms: (å¯é€‰) æœ€å¤§æŒç»­æ—¶é—´ã€‚

        Returns:
            ä¸€ä¸ªåŒ…å«é‡æ„åå¸§æ•°æ®çš„å­—å…¸ï¼Œå¦‚æœå¤±è´¥åˆ™ä¸ºç©ºå­—å…¸ã€‚
        """
        if not self.is_available():
            logger.error("âŒ Tactics2Dåº“ä¸å¯ç”¨ï¼Œæ— æ³•è§£ææ•°æ®é›†")
            return {}

        # è·¯å¾„éªŒè¯ï¼šæ£€æŸ¥ dataset_path æ˜¯å¦å­˜åœ¨
        from pathlib import Path
        dataset_dir = Path(dataset_path)
        if not dataset_dir.exists():
            logger.error(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
            return {}
        if not dataset_dir.is_dir():
            logger.error(f"âŒ æ•°æ®é›†è·¯å¾„ä¸æ˜¯ç›®å½•: {dataset_path}")
            return {}

        logger.info(f"ğŸš€ å¼€å§‹è§£ææ•°æ®é›†: {dataset}, æ–‡ä»¶ID: {file_id}, è·¯å¾„: {dataset_path}")

        try:
            # æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼Œç›®å‰åªå¤„ç† highD æ•°æ®é›†
            if dataset.lower() == 'highd':
                # ä¿®æ­£1: LevelXParserçš„æ„é€ å‡½æ•°éœ€è¦æ•°æ®é›†çš„ *åç§°* (e.g., "highD")
                parser = LevelXParser(dataset)
            else:
                logger.error(f"ä¸æ”¯æŒçš„æ•°æ®é›†ç±»å‹: {dataset}. ç›®å‰åªæ”¯æŒ 'highD'.")
                return {}

            # è°ƒç”¨tactics2dçš„è§£æåŠŸèƒ½
            # ä¿®æ­£2: parse_trajectory éœ€è¦æ˜ç¡®ä¼ é€’ file å’Œ folder å‚æ•°
            # ä¿®æ­£3: ç§»é™¤ä¸æ”¯æŒçš„ 'max_duration_ms' å‚æ•°
            # ä¿®æ­£4: parse_trajectory è¿”å›ä¸€ä¸ªå…ƒç»„ (participants, actual_stamp_range)ï¼Œéœ€è¦è§£åŒ…
            participants, actual_stamp_range = parser.parse_trajectory(
                file=file_id,
                folder=dataset_path,
                stamp_range=stamp_range
            )

            # è®°å½•ç©º participants
            if not participants:
                logger.warning(f"âš ï¸ è§£æå®Œæˆï¼Œä½†æœªä»æ–‡ä»¶ {file_id} ä¸­æå–åˆ°ä»»ä½•å‚ä¸è€…æ•°æ®")
                return {}

            logger.info(f"âœ… æˆåŠŸä»tactics2dè§£æäº† {len(participants)} ä¸ªå‚ä¸è€…")
            logger.info(f"ğŸ• å®é™…æ—¶é—´æˆ³èŒƒå›´: {actual_stamp_range}")

            # è®°å½•æ¯ä¸ªå‚ä¸è€…çš„è½¨è¿¹è§£æçŠ¶æ€
            if participants:
                first_p = next(iter(participants.values()))
                logger.info(f"ğŸ” ç¤ºä¾‹å‚ä¸è€…ä¿¡æ¯: ç±»å‹={type(first_p)}, å±æ€§={list(dir(first_p))}")

            # é‡æ„æ•°æ®ä»¥è¿›è¡Œæµå¼ä¼ è¾“ï¼Œä¼ é€’å®é™…æ—¶é—´æˆ³èŒƒå›´
            restructured_frames = self._restructure_for_streaming(participants, frame_step, actual_stamp_range)
            
            # è®°å½•ç©º frames
            if not restructured_frames:
                logger.warning("âš ï¸ æ•°æ®é‡æ„åç”Ÿæˆçš„å¸§æ•°ä¸º0")
                return {}
            
            return {
                "frames": restructured_frames,
                "total_frames": len(restructured_frames),
                "participant_count": len(participants),
                "frame_step": frame_step,
            }

        except Exception as e:
            logger.error(f"âŒ åœ¨è§£ææ•°æ®é›†æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
            return {}

# åˆ›å»ºä¸€ä¸ªå•ä¾‹ï¼Œæ–¹ä¾¿åœ¨å…¶ä»–åœ°æ–¹ç›´æ¥å¯¼å…¥ä½¿ç”¨
dataset_parser_service = DatasetParserService()
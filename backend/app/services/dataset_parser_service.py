# dataset_parser_service.py - æ•°æ®é›†è§£ææœåŠ¡

# ğŸ“Š æ•°æ®é›†è§£ææœåŠ¡ - ä¸“é—¨å¤„ç†LevelXç­‰æ•°æ®é›†çš„è§£æ
import logging
import math
from typing import Dict, Any, List, Tuple, Optional
from collections import defaultdict
import csv
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥tactics2d
try:
    from tactics2d.dataset_parser import LevelXParser
    TACTICS2D_AVAILABLE = True
    logger.info("âœ… Tactics2Dåº“å·²æˆåŠŸå¯¼å…¥")
except ImportError:
    TACTICS2D_AVAILABLE = False
    logger.warning("âš ï¸ Tactics2Dåº“æœªæ‰¾åˆ°ï¼Œéƒ¨åˆ†åŠŸèƒ½å°†ä¸å¯ç”¨")

class DatasetParserService:
    """
    å°è£…äº†ä¸tactics2dåº“çš„äº¤äº’ï¼Œå¹¶æä¾›äº†å°†æ•°æ®è½¬æ¢ä¸º
    å‰ç«¯æ¸²æŸ“æ‰€éœ€æ ¼å¼çš„æ ¸å¿ƒåŠŸèƒ½ã€‚
    """

    def is_available(self) -> bool:
        """æ£€æŸ¥tactics2dåº“æ˜¯å¦æˆåŠŸå¯¼å…¥"""
        return TACTICS2D_AVAILABLE

    def _log_participant_statistics(self, participants: Dict[int, Any]):
        """
        ç»Ÿè®¡å¹¶æ‰“å°å‚ä¸è€…çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç±»å‹ã€å°ºå¯¸åˆ†å¸ƒç­‰
        
        Args:
            participants: å‚ä¸è€…å­—å…¸
        """
        if not participants:
            logger.warning("âš ï¸ å‚ä¸è€…å­—å…¸ä¸ºç©ºï¼Œæ— æ³•ç»Ÿè®¡")
            return
        
        # ç»Ÿè®¡ä¸åŒç±»å‹
        type_counts = {}
        type_details = {}  # å­˜å‚¨æ¯ç§ç±»å‹çš„è¯¦ç»†ä¿¡æ¯
        
        # å°ºå¯¸ç»Ÿè®¡
        length_stats = {'min': float('inf'), 'max': 0.0, 'sum': 0.0, 'count': 0}
        width_stats = {'min': float('inf'), 'max': 0.0, 'sum': 0.0, 'count': 0}
        
        # è·å–å±æ€§è®¿é—®å™¨
        try:
            sample_participant = next(iter(participants.values()))
            _, _, participant_attr_getter = self._detect_participant_api(sample_participant)
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•æ£€æµ‹å‚ä¸è€…APIï¼Œè·³è¿‡è¯¦ç»†ç»Ÿè®¡: {e}")
            return
        
        # å°è¯•ä» highD çš„ tracksMeta.csv è¯»å–ç±»å‹æ˜ å°„ï¼ˆæ¯”ä¾èµ– Participant.class/type æ›´å¯é ï¼‰
        meta_type_by_id: Dict[int, str] = {}
        try:
            # participant çš„ trajectory é‡Œä¸ä¼šå¸¦ file_id/dataset_pathï¼Œå› æ­¤è¿™é‡Œåªèƒ½åœ¨è°ƒç”¨æ–¹ä¼ å…¥ï¼›
            # è¿™é‡Œä¿æŒå…¼å®¹ï¼šå¦‚æœå¤–éƒ¨æœªè®¾ç½®ï¼Œå°†ä¾èµ– Participant çš„å­—æ®µå…œåº•
            meta_type_by_id = getattr(self, "_last_highd_meta_type_by_id", {}) or {}
        except Exception:
            meta_type_by_id = {}

        # éå†æ‰€æœ‰å‚ä¸è€…è¿›è¡Œç»Ÿè®¡
        for p_id, p_obj in participants.items():
            try:
                # è·å–ç±»å‹
                # æ³¨æ„ï¼štracksMeta.csv çš„å­—æ®µåæ˜¯ 'class'ï¼Œä¸æ˜¯ 'type'
                vehicle_type = meta_type_by_id.get(int(p_id))
                vehicle_type_class = participant_attr_getter(p_obj, 'class')
                vehicle_type_type = participant_attr_getter(p_obj, 'type')
                vehicle_type = vehicle_type or vehicle_type_class or vehicle_type_type
                
                # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•å‰å‡ ä¸ªå‚ä¸è€…çš„ç±»å‹è·å–æƒ…å†µï¼ˆåŒ…æ‹¬Truckï¼‰
                if p_id <= 5 or (vehicle_type_class and vehicle_type_class != 'Car'):
                    logger.debug(f"ğŸ” å‚ä¸è€… {p_id}: class={vehicle_type_class}, type={vehicle_type_type}, æœ€ç»ˆ={vehicle_type}")
                
                # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                if not vehicle_type:
                    vehicle_type = 'Car'  # é»˜è®¤å€¼
                    if p_id <= 5:
                        logger.debug(f"âš ï¸ å‚ä¸è€… {p_id} æ— æ³•è·å–ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤å€¼ 'Car'")
                else:
                    vehicle_type = str(vehicle_type).strip()  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶å»é™¤ç©ºæ ¼
                
                # éªŒè¯ç±»å‹å€¼æ˜¯å¦åˆç†ï¼ˆCar æˆ– Truckï¼‰
                if vehicle_type not in ['Car', 'Truck']:
                    # å¦‚æœç±»å‹ä¸åœ¨é¢„æœŸèŒƒå›´å†…ï¼Œè®°å½•è­¦å‘Šå¹¶ä½¿ç”¨é»˜è®¤å€¼
                    logger.warning(f"âš ï¸ å‚ä¸è€… {p_id} çš„ç±»å‹ '{vehicle_type}' ä¸åœ¨é¢„æœŸèŒƒå›´å†…ï¼ˆåº”ä¸º Car æˆ– Truckï¼‰ï¼Œä½¿ç”¨é»˜è®¤å€¼ 'Car'")
                    vehicle_type = 'Car'
                
                # ç»Ÿè®¡ç±»å‹æ•°é‡
                if vehicle_type not in type_counts:
                    type_counts[vehicle_type] = 0
                    type_details[vehicle_type] = {
                        'ids': [],
                        'lengths': [],
                        'widths': []
                    }
                type_counts[vehicle_type] += 1
                type_details[vehicle_type]['ids'].append(int(p_id))
                
                # è·å–å°ºå¯¸
                # âœ… ä»¥ tactics2d Participant çš„è§„èŒƒå­—æ®µä¸ºå‡†ï¼šlength/widthï¼ˆhighD åŸå§‹ CSV çš„å‘½ååç›´è§‰ï¼Œä½† tactics2d å·²åšå½’ä¸€ï¼‰
                vehicle_length = participant_attr_getter(p_obj, 'length')
                vehicle_width = participant_attr_getter(p_obj, 'width')

                # å…œåº•ï¼šå¦‚æœæŸäº›æ•°æ®é›†/ç‰ˆæœ¬æ²¡æœ‰ length/widthï¼Œåˆ™å°è¯•ä» width/height æ¨æ–­ï¼ˆé•¿ > å®½ï¼‰
                if (vehicle_length is None or vehicle_width is None) and hasattr(p_obj, 'height'):
                    raw_a = getattr(p_obj, 'width', None)
                    raw_b = getattr(p_obj, 'height', None)
                    try:
                        val_a = float(raw_a) if raw_a is not None else 0.0
                        val_b = float(raw_b) if raw_b is not None else 0.0
                        if val_a > 0 and val_b > 0:
                            vehicle_length = max(val_a, val_b)
                            vehicle_width = min(val_a, val_b)
                    except Exception:
                        pass

                # æœ€ç»ˆå…œåº•é»˜è®¤å€¼
                if not vehicle_length or float(vehicle_length) < 1.0:
                    vehicle_length = 4.5  # é»˜è®¤è½¿è½¦é•¿åº¦
                if not vehicle_width or float(vehicle_width) < 0.5:
                    vehicle_width = 2.0  # é»˜è®¤è½¿è½¦å®½åº¦
                
                vehicle_height_attr = None  # tracksMeta.csv æ²¡æœ‰çœŸæ­£çš„"é«˜åº¦"å­—æ®µ
                
                vehicle_length = float(vehicle_length)
                vehicle_width = float(vehicle_width)
                
                # æ›´æ–°å°ºå¯¸ç»Ÿè®¡
                length_stats['min'] = min(length_stats['min'], vehicle_length)
                length_stats['max'] = max(length_stats['max'], vehicle_length)
                length_stats['sum'] += vehicle_length
                length_stats['count'] += 1
                
                width_stats['min'] = min(width_stats['min'], vehicle_width)
                width_stats['max'] = max(width_stats['max'], vehicle_width)
                width_stats['sum'] += vehicle_width
                width_stats['count'] += 1
                
                # è®°å½•åˆ°ç±»å‹è¯¦æƒ…
                type_details[vehicle_type]['lengths'].append(vehicle_length)
                type_details[vehicle_type]['widths'].append(vehicle_width)
                
            except Exception as e:
                logger.debug(f"âš ï¸ ç»Ÿè®¡å‚ä¸è€… {p_id} æ—¶å‡ºé”™: {e}")
                continue
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        logger.info("=" * 60)
        logger.info("ğŸ“Š å‚ä¸è€…è¯¦ç»†ç»Ÿè®¡:")
        logger.info(f"   ğŸ‘¥ æ€»å‚ä¸è€…æ•°: {len(participants)}")
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        logger.info("   ğŸš— å‚ä¸è€…ç±»å‹åˆ†å¸ƒ:")
        sorted_types = sorted(type_counts.items(), key=lambda x: x[1], reverse=True)
        for vehicle_type, count in sorted_types:
            percentage = (count / len(participants)) * 100
            logger.info(f"      â€¢ {vehicle_type}: {count} ä¸ª ({percentage:.1f}%)")
            
            # æ˜¾ç¤ºè¯¥ç±»å‹çš„å°ºå¯¸èŒƒå›´
            if vehicle_type in type_details:
                lengths = type_details[vehicle_type]['lengths']
                widths = type_details[vehicle_type]['widths']
                if lengths and widths:
                    avg_length = sum(lengths) / len(lengths)
                    avg_width = sum(widths) / len(widths)
                    min_length = min(lengths)
                    max_length = max(lengths)
                    min_width = min(widths)
                    max_width = max(widths)
                    logger.info(f"        å°ºå¯¸èŒƒå›´: é•¿åº¦ {min_length:.2f}-{max_length:.2f}m (å¹³å‡ {avg_length:.2f}m), "
                              f"å®½åº¦ {min_width:.2f}-{max_width:.2f}m (å¹³å‡ {avg_width:.2f}m)")
        
        # æ•´ä½“å°ºå¯¸ç»Ÿè®¡
        if length_stats['count'] > 0:
            avg_length = length_stats['sum'] / length_stats['count']
            avg_width = width_stats['sum'] / width_stats['count']
            logger.info("   ğŸ“ æ•´ä½“å°ºå¯¸ç»Ÿè®¡:")
            logger.info(f"      é•¿åº¦èŒƒå›´: {length_stats['min']:.2f} - {length_stats['max']:.2f}m (å¹³å‡ {avg_length:.2f}m)")
            logger.info(f"      å®½åº¦èŒƒå›´: {width_stats['min']:.2f} - {width_stats['max']:.2f}m (å¹³å‡ {avg_width:.2f}m)")
        
        logger.info("=" * 60)

    def _detect_participant_api(self, sample_participant: Any) -> tuple:
        """
        æ£€æµ‹Participantå¯¹è±¡çš„APIæ¥å£ï¼Œé¿å…åœ¨å¾ªç¯ä¸­åå¤æ£€æŸ¥
        
        Args:
            sample_participant: ä¸€ä¸ªæ ·æœ¬å‚ä¸è€…å¯¹è±¡
            
        Returns:
            (get_state_method, state_attr_getter, participant_attr_getter) å…ƒç»„
            - get_state_method: è·å–çŠ¶æ€çš„æ–¹æ³•ï¼ˆcallableï¼‰
            - state_attr_getter: ä»stateå¯¹è±¡è·å–å±æ€§çš„å‡½æ•°
            - participant_attr_getter: ä»participantå¯¹è±¡è·å–é™æ€å±æ€§çš„å‡½æ•°
        """
        # æ£€æµ‹è·å–çŠ¶æ€çš„æ–¹æ³•
        # âš ï¸ é‡è¦ï¼šä¸èƒ½ç›´æ¥è¿”å› sample_participant.get_state...ï¼ˆå®ƒæ˜¯â€œç»‘å®šæ–¹æ³•â€ï¼‰
        # å¦åˆ™åœ¨å¾ªç¯é‡Œä¼šé”™è¯¯åœ°å¯¹æ‰€æœ‰å‚ä¸è€…éƒ½è¯»å–åŒä¸€ä¸ª sample_participant çš„çŠ¶æ€ï¼Œå¯¼è‡´â€œæ²¡æœ‰è½¦/è½¦éƒ½é‡å â€ç­‰ä¸¥é‡é—®é¢˜ã€‚
        if hasattr(sample_participant, 'get_state_at_timestamp'):
            def get_state_method(participant, timestamp):
                return participant.get_state_at_timestamp(timestamp)
        elif hasattr(sample_participant, 'get_state'):
            def get_state_method(participant, timestamp):
                return participant.get_state(timestamp)
        else:
            raise AttributeError("Participantå¯¹è±¡ç¼ºå°‘get_stateæ–¹æ³•")
        
        # æ£€æµ‹Stateå¯¹è±¡çš„å±æ€§åç§°ï¼ˆåªæ£€æµ‹ä¸€æ¬¡ï¼‰
        if not hasattr(sample_participant, 'is_active'):
            raise AttributeError("Participantå¯¹è±¡ç¼ºå°‘is_activeæ–¹æ³•")
        
        # è·å–ä¸€ä¸ªæ ·æœ¬stateæ¥æ£€æµ‹å±æ€§
        # å°è¯•è·å–ç¬¬ä¸€ä¸ªå¯èƒ½çš„æ—¶é—´æˆ³çš„çŠ¶æ€
        sample_state = None
        detection_error = None
        try:
            # å°è¯•è·å–ä¸€ä¸ªçŠ¶æ€æ¥æ£€æµ‹å±æ€§ç»“æ„
            if hasattr(sample_participant, 'trajectory'):
                traj = sample_participant.trajectory
                if hasattr(traj, 'stamps') and traj.stamps:
                    sample_timestamp = traj.stamps[0]
                    sample_state = get_state_method(sample_participant, sample_timestamp)
                    if sample_state is None:
                        detection_error = "get_state_methodè¿”å›None"
                else:
                    detection_error = "trajectory.stampsä¸ºç©ºæˆ–ä¸å­˜åœ¨"
            else:
                detection_error = "Participantå¯¹è±¡æ²¡æœ‰trajectoryå±æ€§"
        except Exception as e:
            detection_error = f"è·å–æ ·æœ¬çŠ¶æ€æ—¶å‡ºé”™: {str(e)}"
            logger.debug(f"Stateå±æ€§æ£€æµ‹è¯¦ç»†é”™è¯¯: {e}", exc_info=True)
        
        if sample_state is None:
            # å¦‚æœæ— æ³•è·å–æ ·æœ¬ï¼Œä½¿ç”¨é»˜è®¤å±æ€§åï¼ˆTactics2Dæ ‡å‡†ï¼‰
            # è¿™é€šå¸¸æ˜¯å¯ä»¥æ¥å—çš„ï¼Œå› ä¸ºTactics2Dçš„æ ‡å‡†å±æ€§å°±æ˜¯ x, y, vx, vy, heading
            logger.info(f"â„¹ï¸ ä½¿ç”¨é»˜è®¤Stateå±æ€§å (x, y, vx, vy, heading). åŸå› : {detection_error or 'æ— æ³•è·å–æ ·æœ¬çŠ¶æ€'}")
            def attr_getter(state, attr_name):
                return getattr(state, attr_name, 0.0)
        else:
            # æ£€æµ‹å®é™…å±æ€§å
            state_attrs = {}
            for standard_name in ['x', 'y', 'vx', 'vy', 'heading']:
                # å°è¯•æ ‡å‡†åç§°
                if hasattr(sample_state, standard_name):
                    state_attrs[standard_name] = standard_name
                # å°è¯•æ›¿ä»£åç§°
                elif standard_name == 'x' and hasattr(sample_state, 'position_x'):
                    state_attrs[standard_name] = 'position_x'
                elif standard_name == 'y' and hasattr(sample_state, 'position_y'):
                    state_attrs[standard_name] = 'position_y'
                elif standard_name == 'vx' and hasattr(sample_state, 'velocity_x'):
                    state_attrs[standard_name] = 'velocity_x'
                elif standard_name == 'vy' and hasattr(sample_state, 'velocity_y'):
                    state_attrs[standard_name] = 'velocity_y'
                elif standard_name == 'heading' and hasattr(sample_state, 'orientation'):
                    state_attrs[standard_name] = 'orientation'
                else:
                    state_attrs[standard_name] = standard_name  # ä½¿ç”¨é»˜è®¤å€¼0.0
            
            def attr_getter(state, attr_name):
                actual_attr = state_attrs.get(attr_name, attr_name)
                return getattr(state, actual_attr, 0.0)
        
        # æ£€æµ‹Participantå¯¹è±¡çš„é™æ€å±æ€§ï¼ˆwidth, height, typeç­‰ï¼‰
        # è¿™äº›å±æ€§é€šå¸¸ä¸ä¼šå˜åŒ–ï¼Œå¯ä»¥ä»participantå¯¹è±¡ç›´æ¥è·å–
        debug_dump_flag = {'logged': False}  # ä»…åœ¨é¦–æ¬¡ç¼ºå¤±æ—¶æ‰“å°ä¸€æ¬¡è¯¦ç»†ä¿¡æ¯ï¼Œé¿å…åˆ·å±

        def participant_attr_getter(participant, attr_name):
            """ä»Participantå¯¹è±¡è·å–é™æ€å±æ€§"""
            # å°è¯•å¤šç§å¯èƒ½çš„å±æ€§å
            # æ³¨æ„ï¼štracksMeta.csv çš„å­—æ®µåæ˜¯ 'class'ï¼Œä¸æ˜¯ 'type'
            possible_names = {
                'width': ['width', 'w', 'vehicle_width'],
                'height': ['height', 'h', 'vehicle_height', 'length'],  # æ³¨æ„ï¼šhighDçš„heightå®é™…æ˜¯è½¦å®½ï¼ˆä¸â€œé•¿åº¦/å®½åº¦â€å‘½åå®¹æ˜“æ··æ·†ï¼‰
                'length': ['length', 'l', 'vehicle_length'],
                # type & class å­—æ®µå¸¸è§çš„é‡å‘½åï¼štype_, class_
                'type': ['type', 'type_', 'class', 'class_', 'vehicle_type', 'vehicle_class'],  # type å¯ä»¥å°è¯• class
                'class': ['class', 'class_', 'type', 'type_', 'vehicle_class', 'vehicle_type']  # class ä¼˜å…ˆå°è¯• 'class'ï¼Œå› ä¸ºè¿™æ˜¯CSVçš„å®é™…å­—æ®µå
            }
            
            # è·å–å¯èƒ½çš„å±æ€§ååˆ—è¡¨
            candidates = possible_names.get(attr_name, [attr_name])
            
            for candidate in candidates:
                if hasattr(participant, candidate):
                    value = getattr(participant, candidate)
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
                    if isinstance(value, str):
                        return value
                    # å¦‚æœæ˜¯æ•°å€¼ï¼Œè½¬æ¢ä¸ºfloat
                    try:
                        return float(value)
                    except (ValueError, TypeError):
                        return value

            # æ£€æŸ¥ custom_tags å­—æ®µï¼ˆTactics2D å¯èƒ½æŠŠç±»å‹æ”¾åœ¨è¿™é‡Œï¼‰
            try:
                if hasattr(participant, "custom_tags"):
                    tags = getattr(participant, "custom_tags")
                    if isinstance(tags, dict):
                        # ä¼˜å…ˆåŒ¹é… attr_nameï¼Œå…¶æ¬¡åŒ¹é… 'class'/'type'
                        if attr_name in tags:
                            return tags[attr_name]
                        if attr_name == 'class' and 'class' in tags:
                            return tags['class']
                        if attr_name == 'type' and 'type' in tags:
                            return tags['type']
            except Exception:
                pass

            # å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ï¼Œæ‰“å°ä¸€æ¬¡è°ƒè¯•ä¿¡æ¯ï¼Œå¸®åŠ©å®šä½çœŸå®å­—æ®µå
            if attr_name in ('class', 'type') and not debug_dump_flag['logged']:
                try:
                    debug_dump_flag['logged'] = True
                    attrs = dir(participant)
                    attr_keys = list(getattr(participant, "__dict__", {}).keys())
                    logger.info(f"ğŸ” æœªæ‰¾åˆ°å±æ€§ '{attr_name}'ï¼Œæ‰“å°Participantè°ƒè¯•ä¿¡æ¯ç”¨äºæ’æŸ¥å­—æ®µæ˜ å°„é—®é¢˜")
                    logger.info(f"   dir(participant): {attrs}")
                    logger.info(f"   participant.__dict__.keys(): {attr_keys}")
                    if hasattr(participant, "custom_tags"):
                        logger.info(f"   participant.custom_tags: {getattr(participant, 'custom_tags')}")
                except Exception:
                    pass
            
            # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›é»˜è®¤å€¼
            # âš ï¸ é‡è¦ï¼š'type' å’Œ 'class' ä¸è®¾ç½®é»˜è®¤å€¼ï¼Œè¿”å› None
            # è¿™æ ·å¯ä»¥åŒºåˆ†"æ‰¾ä¸åˆ°å±æ€§"å’Œ"å±æ€§å€¼ä¸ºé»˜è®¤å€¼"çš„æƒ…å†µ
            # è°ƒç”¨è€…éœ€è¦æ ¹æ®å®é™…æƒ…å†µå¤„ç† None å€¼ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœæ‰¾ä¸åˆ° classï¼Œå†ä½¿ç”¨é»˜è®¤å€¼ 'Car'ï¼‰
            defaults = {
                'width': 2.0,
                'height': 1.8,
                'length': 4.5,
                # 'type' å’Œ 'class' ä¸è®¾ç½®é»˜è®¤å€¼ï¼Œè¿”å› None
            }
            return defaults.get(attr_name, None)
        
        return get_state_method, attr_getter, participant_attr_getter

    def _load_highd_tracks_meta_type_map(self, dataset_path: str, file_id: int) -> Dict[int, str]:
        """
        ç›´æ¥è¯»å– highD çš„ %02d_tracksMeta.csvï¼Œæå– idâ†’class(Car/Truck) æ˜ å°„ã€‚
        è¿™æ˜¯ç›®å‰æœ€å¯é çš„è½¦è¾†ç±»å‹æ¥æºï¼ˆtactics2d Participant å¾€å¾€ä¸æš´éœ² class/typeï¼‰ã€‚
        """
        try:
            meta_path = Path(dataset_path) / f"{int(file_id):02d}_tracksMeta.csv"
            if not meta_path.exists():
                logger.warning(f"âš ï¸ tracksMeta.csv ä¸å­˜åœ¨ï¼Œæ— æ³•å»ºç«‹ç±»å‹æ˜ å°„: {meta_path}")
                return {}

            type_by_id: Dict[int, str] = {}
            with meta_path.open("r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    try:
                        rid = int(row.get("id", "").strip())
                    except Exception:
                        continue
                    cls = (row.get("class") or "").strip()
                    if cls in ("Car", "Truck"):
                        type_by_id[rid] = cls

            if type_by_id:
                # ç»™ç»Ÿè®¡/é‡æ„é˜¶æ®µå¤ç”¨ï¼ˆé¿å…æ”¹å¤§é‡å‡½æ•°ç­¾åï¼‰
                self._last_highd_meta_type_by_id = type_by_id
                logger.info(f"âœ… ä» tracksMeta.csv å»ºç«‹ç±»å‹æ˜ å°„: {len(type_by_id)} æ¡")
            else:
                logger.warning("âš ï¸ tracksMeta.csv ä¸­æœªè§£æå‡ºä»»ä½•æœ‰æ•ˆ class å­—æ®µï¼ˆCar/Truckï¼‰")

            return type_by_id
        except Exception as e:
            logger.warning(f"âš ï¸ è¯»å– tracksMeta.csv å»ºç«‹ç±»å‹æ˜ å°„å¤±è´¥: {e}")
            return {}

    def _restructure_for_streaming(
        self, 
        participants: Dict[int, Any], 
        frame_step: int, 
        actual_stamp_range: Tuple[int, int] = None,
        perception_range: Optional[float] = None,
        reference_point: Optional[Tuple[float, float]] = None,
        coordinate_scale: float = 1.0
    ) -> Dict[int, List[Dict]]:
        """
        ä¼˜åŒ–åçš„æ•°æ®é‡æ„æ–¹æ³•ï¼šç›´æ¥æŒ‰æ­¥é•¿é‡‡æ ·ï¼Œé¿å…æ— æ•ˆè®¡ç®—ã€‚
        
        æ€§èƒ½ä¼˜åŒ–ï¼š
        1. ç›´æ¥æŒ‰effective_stepè·³è·ƒå¾ªç¯ï¼Œåªè®¡ç®—éœ€è¦çš„å¸§
        2. é¢„å…ˆæ£€æµ‹APIæ¥å£ï¼Œé¿å…å¾ªç¯ä¸­åå¤hasattr/getattr
        3. ç§»é™¤å¤šä½™çš„æ’åºæ“ä½œï¼ˆrangeæœ¬èº«æœ‰åºï¼Œå­—å…¸ä¿æŒæ’å…¥é¡ºåºï¼‰
        
        Args:
            participants: tactics2dçš„parse_trajectoryè¿”å›çš„åŸå§‹å‚ä¸è€…å­—å…¸
            frame_step: æ•°æ®å¤„ç†çš„å¸§é—´éš”æ­¥é•¿ï¼ˆå‰ç«¯æ’­æ”¾é€Ÿåº¦å€æ•°ï¼‰
            actual_stamp_range: å®é™…çš„æ—¶é—´æˆ³èŒƒå›´ï¼ˆæ¥è‡ªparse_trajectoryè¿”å›å€¼ï¼‰
            perception_range: (å¯é€‰) æ„ŸçŸ¥èŒƒå›´ï¼ˆç±³ï¼‰ï¼Œç”¨äºç©ºé—´è£å‰ª
            reference_point: (å¯é€‰) å‚è€ƒç‚¹åæ ‡ (x, y)ï¼Œç”¨äºè®¡ç®—è·ç¦»
            coordinate_scale: (å¯é€‰) åæ ‡ç¼©æ”¾æ¯”ä¾‹ï¼Œç”¨äºä¸åœ°å›¾åæ ‡ç³»ç»ŸåŒ¹é…ï¼ˆé»˜è®¤1.0ï¼‰
            
        Returns:
            ä¸€ä¸ªä»¥å¸§å·ä¸ºé”®ï¼ˆä»0å¼€å§‹ï¼‰ï¼Œå€¼ä¸ºè¯¥å¸§æ‰€æœ‰è½¦è¾†çŠ¶æ€åˆ—è¡¨çš„å­—å…¸
        """
        if not participants or not actual_stamp_range:
            return {}
        
        start_time, end_time = actual_stamp_range
        
        # LevelXæ•°æ®é›†ï¼ˆhighDç­‰ï¼‰çš„é‡‡æ ·é¢‘ç‡æ˜¯25Hzï¼Œå³æ¯40msä¸€å¸§
        # å‚è€ƒï¼šhttps://tactics2d.readthedocs.io/en/latest/api/dataset_parser/
        BASE_TIME_STEP = 40  # æ¯«ç§’
        
        # è®¡ç®—å®é™…é‡‡æ ·é—´éš”ï¼šåŸºç¡€é—´éš” Ã— å¸§æ­¥é•¿
        # ä¾‹å¦‚ frame_step=5 æ—¶ï¼Œæ¯200msé‡‡æ ·ä¸€æ¬¡ï¼ˆ5å€é€Ÿæ’­æ”¾ï¼‰
        effective_step = BASE_TIME_STEP * frame_step
        
        logger.info(f"ğŸ”„ ä¼˜åŒ–é‡æ„: {len(participants)} ä¸ªå‚ä¸è€…, æ—¶é—´èŒƒå›´ {start_time}-{end_time}ms")
        logger.info(f"   é‡‡æ ·é—´éš”: {effective_step}ms (åŸºç¡€: {BASE_TIME_STEP}ms Ã— æ­¥é•¿: {frame_step})")
        
        # é¢„å…ˆæ£€æµ‹APIæ¥å£ï¼ˆåªæ£€æµ‹ä¸€æ¬¡ï¼Œä¸åœ¨å¾ªç¯ä¸­é‡å¤æ£€æŸ¥ï¼‰
        try:
            sample_participant = next(iter(participants.values()))
            get_state_method, state_attr_getter, participant_attr_getter = self._detect_participant_api(sample_participant)
            logger.debug("âœ… APIæ£€æµ‹å®Œæˆ: get_stateæ–¹æ³•=per-participant wrapper")
        except Exception as e:
            logger.error(f"âŒ APIæ£€æµ‹å¤±è´¥: {e}")
            return {}
        
        sampled_frames = {}
        frame_index = 0  # å‰ç«¯éœ€è¦çš„è¿ç»­å¸§å·ï¼ˆä»0å¼€å§‹ï¼‰
        
        # ç›´æ¥æŒ‰effective_stepè·³è·ƒå¾ªç¯ï¼Œåªè®¡ç®—éœ€è¦çš„å¸§
        # Python 3.7+ å­—å…¸ä¿æŒæ’å…¥é¡ºåºï¼Œæ— éœ€é¢å¤–æ’åº
        # å°è¯•ä» highD çš„ tracksMeta.csv è¯»å–ç±»å‹æ˜ å°„ï¼ˆå¦‚æœä¸Šå±‚å·²åŠ è½½ï¼‰
        meta_type_by_id: Dict[int, str] = {}
        try:
            meta_type_by_id = getattr(self, "_last_highd_meta_type_by_id", {}) or {}
        except Exception:
            meta_type_by_id = {}

        for timestamp in range(int(start_time), int(end_time), effective_step):
            frame_participants = []
            
            for p_id, p_obj in participants.items():
                try:
                    # å¿«é€Ÿæ£€æŸ¥æ´»è·ƒçŠ¶æ€ï¼ˆå·²ç¡®è®¤æœ‰is_activeæ–¹æ³•ï¼‰
                    if not p_obj.is_active(timestamp):
                        continue
                    
                    # è·å–çŠ¶æ€ï¼ˆå·²ç¡®è®¤æ–¹æ³•å­˜åœ¨ï¼‰
                    state = get_state_method(p_obj, timestamp)
                    if state is None:
                        continue
                    
                    # æå–é™æ€å±æ€§ï¼ˆå°ºå¯¸å’Œç±»å‹ï¼‰- è¿™äº›å±æ€§ä¸ä¼šéšæ—¶é—´å˜åŒ–
                    # âœ… ä»¥ tactics2d Participant çš„è§„èŒƒå­—æ®µä¸ºå‡†ï¼šlength/width
                    # è¯´æ˜ï¼šhighD åŸå§‹ CSV çš„ width/height å‘½åç¡®å®â€œåç›´è§‰â€ï¼Œä½† tactics2d å·²å½’ä¸€ä¸º length/widthã€‚
                    
                    # è·å–è½¦è¾†ç±»å‹ï¼šä¼˜å…ˆä½¿ç”¨ tracksMeta.csv çš„ class æ˜ å°„ï¼Œå…¶æ¬¡å°è¯• Participant å­—æ®µ
                    vehicle_type = meta_type_by_id.get(int(p_id))
                    vehicle_type = vehicle_type or participant_attr_getter(p_obj, 'class') or participant_attr_getter(p_obj, 'type')
                    if not vehicle_type:
                        vehicle_type = 'Car'  # é»˜è®¤å€¼
                    else:
                        vehicle_type = str(vehicle_type).strip()
                        # éªŒè¯ç±»å‹å€¼
                        if vehicle_type not in ['Car', 'Truck']:
                            vehicle_type = 'Car'  # å¦‚æœç±»å‹å¼‚å¸¸ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    
                    vehicle_length = participant_attr_getter(p_obj, 'length')
                    vehicle_width = participant_attr_getter(p_obj, 'width')

                    # å…œåº•ï¼šå¦‚æœç¼ºå¤± length/widthï¼Œå°è¯•ç”¨ width/height æ¨æ–­ï¼ˆé•¿ > å®½ï¼‰
                    if (vehicle_length is None or vehicle_width is None) and hasattr(p_obj, 'height'):
                        raw_a = getattr(p_obj, 'width', None)
                        raw_b = getattr(p_obj, 'height', None)
                        try:
                            val_a = float(raw_a) if raw_a is not None else 0.0
                            val_b = float(raw_b) if raw_b is not None else 0.0
                            if val_a > 0 and val_b > 0:
                                vehicle_length = max(val_a, val_b)
                                vehicle_width = min(val_a, val_b)
                        except Exception:
                            pass
                    
                    # 3. å…œåº•é»˜è®¤å€¼ï¼ˆé˜²æ­¢å¼‚å¸¸æ•°æ®ï¼‰
                    if not vehicle_length or vehicle_length < 1.0:
                        vehicle_length = 4.5  # é»˜è®¤è½¿è½¦é•¿åº¦
                    if not vehicle_width or vehicle_width < 0.5:
                        vehicle_width = 2.0  # é»˜è®¤è½¿è½¦å®½åº¦
                    
                    # è·å–åŸå§‹åæ ‡ï¼ˆæœªç¼©æ”¾ï¼‰
                    x_raw = float(state_attr_getter(state, 'x'))
                    y_raw = float(state_attr_getter(state, 'y'))
                    
                    # ç©ºé—´è¿‡æ»¤ï¼šå¦‚æœè®¾ç½®äº†perception_rangeï¼Œåªä¿ç•™èŒƒå›´å†…çš„è½¦è¾†
                    # æ³¨æ„ï¼šè¿‡æ»¤ä½¿ç”¨åŸå§‹åæ ‡ï¼ˆç±³ï¼‰ï¼Œå› ä¸ºperception_rangeä¹Ÿæ˜¯ä»¥ç±³ä¸ºå•ä½
                    if perception_range and reference_point:
                        ref_x, ref_y = reference_point
                        distance = math.sqrt((x_raw - ref_x)**2 + (y_raw - ref_y)**2)
                        if distance > perception_range:
                            continue  # è·³è¿‡è¶…å‡ºæ„ŸçŸ¥èŒƒå›´çš„è½¦è¾†
                    
                    # âœ… è½¦è¾†è½¨è¿¹åœ¨ highD ä¸­æœ¬èº«å°±æ˜¯ç±³åˆ¶åæ ‡ï¼›ä¸è¦å†ä¹˜ coordinate_scaleï¼ˆè¯¥å‚æ•°ç”¨äºåœ°å›¾åº¦â†’ç±³çš„ç¼©æ”¾ï¼‰
                    x_scaled = x_raw
                    y_scaled = y_raw
                    
                    # ç›´æ¥ä½¿ç”¨é¢„æ£€æµ‹çš„å±æ€§è®¿é—®å™¨ï¼ˆé¿å…getattrå¼€é”€ï¼‰
                    frame_participants.append({
                        "id": int(p_id),
                        "x": round(x_scaled, 3),  # åº”ç”¨ç¼©æ”¾åçš„åæ ‡
                        "y": round(y_scaled, 3),  # åº”ç”¨ç¼©æ”¾åçš„åæ ‡
                        "vx": round(float(state_attr_getter(state, 'vx')), 3),  # é€Ÿåº¦é€šå¸¸ä¸éœ€è¦ç¼©æ”¾
                        "vy": round(float(state_attr_getter(state, 'vy')), 3),  # é€Ÿåº¦é€šå¸¸ä¸éœ€è¦ç¼©æ”¾
                        "heading": round(float(state_attr_getter(state, 'heading')), 3),
                        # æ–°å¢ï¼šè½¦è¾†å°ºå¯¸å’Œç±»å‹ä¿¡æ¯ï¼ˆhighDï¼šå•ä½ç±³ï¼‰
                        "length": round(float(vehicle_length), 2) if vehicle_length else 4.5,
                        "width": round(float(vehicle_width), 2) if vehicle_width else 2.0,
                        "type": str(vehicle_type) if vehicle_type else "Car"
                    })
                    
                except Exception as participant_error:
                    # åªåœ¨è°ƒè¯•æ¨¡å¼ä¸‹è®°å½•è¯¦ç»†é”™è¯¯
                    logger.debug(f"âš ï¸ å‚ä¸è€… {p_id} åœ¨æ—¶é—´æˆ³ {timestamp} æ—¶å‡ºé”™: {participant_error}")
                    continue
            
            # æ— è®ºè¿™ä¸€å¸§æœ‰æ²¡æœ‰è½¦ï¼Œéƒ½åˆ›å»ºå¸§ï¼ˆä¿æŒå¸§ç´¢å¼•è¿ç»­ï¼‰
            # å‰ç«¯æ’­æ”¾å™¨éœ€è¦è¿ç»­çš„å¸§å·
            sampled_frames[frame_index] = {
                "timestamp": timestamp,
                "vehicles": frame_participants
            }
            frame_index += 1
        
        if not sampled_frames:
            logger.warning("âš ï¸ æ•°æ®é‡æ„åæ²¡æœ‰ç”Ÿæˆä»»ä½•å¸§")
            return {}
        
        logger.info(f"âœ… é‡æ„å®Œæˆ: ç”Ÿæˆ {len(sampled_frames)} å¸§ (ç›´æ¥é‡‡æ ·ï¼Œæ— æµªè´¹è®¡ç®—)")
        return sampled_frames

    def parse_dataset_for_session(
        self,
        dataset: str,
        file_id: int,
        dataset_path: str,
        frame_step: int,
        stamp_range: Tuple[int, int] = None,
        max_duration_ms: int = None,
        perception_range: Optional[float] = None,
        coordinate_scale: float = 1.0
    ) -> Dict[str, Any]:
        """
        è§£ææŒ‡å®šçš„æ•°æ®é›†æ–‡ä»¶ï¼Œå¹¶ä¸ºWebSocketä¼šè¯å‡†å¤‡æ•°æ®ã€‚

        Args:
            dataset: æ•°æ®é›†ç±»å‹ (ä¾‹å¦‚, "levelx")ã€‚
            file_id: æ•°æ®é›†æ–‡ä»¶IDã€‚
            dataset_path: æ•°æ®é›†æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•ã€‚
            frame_step: å¸§é—´éš”ã€‚
            stamp_range: (å¯é€‰) æ—¶é—´æˆ³èŒƒå›´ã€‚
            max_duration_ms: (å¯é€‰) æœ€å¤§æŒç»­æ—¶é—´ã€‚
            perception_range: (å¯é€‰) æ„ŸçŸ¥èŒƒå›´ï¼ˆç±³ï¼‰ã€‚
            coordinate_scale: (å¯é€‰) åæ ‡ç¼©æ”¾æ¯”ä¾‹ï¼Œç”¨äºä¸åœ°å›¾åæ ‡ç³»ç»ŸåŒ¹é…ï¼ˆé»˜è®¤1.0ï¼‰ã€‚

        Returns:
            ä¸€ä¸ªåŒ…å«é‡æ„åå¸§æ•°æ®çš„å­—å…¸ï¼Œå¦‚æœå¤±è´¥åˆ™ä¸ºç©ºå­—å…¸ã€‚
        """
        if not self.is_available():
            logger.error("âŒ Tactics2Dåº“ä¸å¯ç”¨ï¼Œæ— æ³•è§£ææ•°æ®é›†")
            return {}

        # è·¯å¾„éªŒè¯ï¼šæ£€æŸ¥ dataset_path æ˜¯å¦å­˜åœ¨
        dataset_dir = Path(dataset_path)
        if not dataset_dir.exists():
            logger.error(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
            return {}
        if not dataset_dir.is_dir():
            logger.error(f"âŒ æ•°æ®é›†è·¯å¾„ä¸æ˜¯ç›®å½•: {dataset_path}")
            return {}

        logger.info(f"ğŸš€ å¼€å§‹è§£ææ•°æ®é›†: {dataset}, æ–‡ä»¶ID: {file_id}, è·¯å¾„: {dataset_path}")

        try:
            # æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼Œç›®å‰åªå¤„ç† highD æ•°æ®é›†
            # LevelXParser æ„é€ å‡½æ•°éœ€è¦æ­£ç¡®çš„æ•°æ®é›†åç§°ï¼ˆå¤§å°å†™æ•æ„Ÿï¼‰
            # æ–‡æ¡£ï¼šhttps://tactics2d.readthedocs.io/en/latest/api/dataset_parser/
            # LevelXç³»åˆ—åŒ…æ‹¬ï¼šhighD, inD, rounD, exiD, uniD
            dataset_lower = dataset.lower()
            if dataset_lower == 'highd':
                # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å¤§å°å†™æ ¼å¼ï¼ˆhighDï¼‰
                parser = LevelXParser("highD")
            elif dataset_lower in ['ind', 'round', 'exid', 'unid']:
                # æ”¯æŒå…¶ä»–LevelXæ•°æ®é›†
                dataset_name_map = {
                    'ind': 'inD',
                    'round': 'rounD',
                    'exid': 'exiD',
                    'unid': 'uniD'
                }
                parser = LevelXParser(dataset_name_map[dataset_lower])
            else:
                logger.error(f"ä¸æ”¯æŒçš„æ•°æ®é›†ç±»å‹: {dataset}. LevelXParseræ”¯æŒ: highD, inD, rounD, exiD, uniD")
                return {}

            # è°ƒç”¨tactics2dçš„è§£æåŠŸèƒ½
            # ä¿®æ­£2: parse_trajectory éœ€è¦æ˜ç¡®ä¼ é€’ file å’Œ folder å‚æ•°
            # ä¿®æ­£3: ç§»é™¤ä¸æ”¯æŒçš„ 'max_duration_ms' å‚æ•°
            # ä¿®æ­£4: parse_trajectory è¿”å›ä¸€ä¸ªå…ƒç»„ (participants, actual_stamp_range)ï¼Œéœ€è¦è§£åŒ…
            participants, actual_stamp_range = parser.parse_trajectory(
                file=file_id,
                folder=dataset_path,
                stamp_range=stamp_range
            )

            # è®°å½•ç©º participants
            if not participants:
                logger.warning(f"âš ï¸ è§£æå®Œæˆï¼Œä½†æœªä»æ–‡ä»¶ {file_id} ä¸­æå–åˆ°ä»»ä½•å‚ä¸è€…æ•°æ®")
                return {}

            logger.info(f"âœ… æˆåŠŸä»tactics2dè§£æäº† {len(participants)} ä¸ªå‚ä¸è€…")
            logger.info(f"ğŸ• å®é™…æ—¶é—´æˆ³èŒƒå›´: {actual_stamp_range}")

            # easy fix: highD ç±»å‹æ˜ å°„ç›´æ¥ä» tracksMeta.csv è¯»å–
            if dataset_lower == "highd":
                self._load_highd_tracks_meta_type_map(dataset_path=dataset_path, file_id=file_id)
            
            # ç»Ÿè®¡å‚ä¸è€…è¯¦ç»†ä¿¡æ¯
            self._log_participant_statistics(participants)

            # è®¡ç®—å‚è€ƒç‚¹ï¼ˆç”¨äºperception_rangeç©ºé—´è¿‡æ»¤ï¼‰
            # å¦‚æœè®¾ç½®äº†perception_rangeï¼Œéœ€è¦è®¡ç®—ä¸€ä¸ªå‚è€ƒç‚¹ï¼ˆä½¿ç”¨ç¬¬ä¸€å¸§æ‰€æœ‰å‚ä¸è€…çš„å¹³å‡ä½ç½®ï¼‰
            reference_point = None
            if perception_range and perception_range > 0:
                try:
                    # è·å–ç¬¬ä¸€ä¸ªå‚ä¸è€…çš„ç¬¬ä¸€ä¸ªæ—¶é—´æˆ³
                    sample_participant = next(iter(participants.values()))
                    get_state_method = None
                    # å¤ç”¨ç»Ÿä¸€çš„ API æ£€æµ‹é€»è¾‘ï¼ˆè¿”å› per-participant wrapperï¼‰
                    try:
                        get_state_method, _, _ = self._detect_participant_api(sample_participant)
                    except Exception:
                        get_state_method = None
                    
                    if get_state_method and hasattr(sample_participant, 'trajectory'):
                        traj = sample_participant.trajectory
                        if hasattr(traj, 'stamps') and traj.stamps:
                            first_timestamp = traj.stamps[0]
                            # è·å–æ‰€æœ‰å‚ä¸è€…åœ¨ç¬¬ä¸€å¸§çš„ä½ç½®ï¼Œè®¡ç®—ä¸­å¿ƒç‚¹
                            positions = []
                            for p_obj in participants.values():
                                if p_obj.is_active(first_timestamp):
                                    state = get_state_method(p_obj, first_timestamp)
                                    if state:
                                        try:
                                            x = getattr(state, 'x', None) or getattr(state, 'position_x', 0)
                                            y = getattr(state, 'y', None) or getattr(state, 'position_y', 0)
                                            positions.append((float(x), float(y)))
                                        except:
                                            pass
                            if positions:
                                ref_x = sum(p[0] for p in positions) / len(positions)
                                ref_y = sum(p[1] for p in positions) / len(positions)
                                reference_point = (ref_x, ref_y)
                                logger.info(f"ğŸ“ è®¡ç®—å‚è€ƒç‚¹: ({ref_x:.2f}, {ref_y:.2f}), æ„ŸçŸ¥èŒƒå›´: {perception_range}ç±³")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ— æ³•è®¡ç®—å‚è€ƒç‚¹ï¼Œå°†ç¦ç”¨ç©ºé—´è¿‡æ»¤: {e}")

            # é‡æ„æ•°æ®ä»¥è¿›è¡Œæµå¼ä¼ è¾“ï¼Œä¼ é€’å®é™…æ—¶é—´æˆ³èŒƒå›´
            restructured_frames = self._restructure_for_streaming(
                participants, 
                frame_step, 
                actual_stamp_range,
                perception_range=perception_range,
                reference_point=reference_point,
                coordinate_scale=coordinate_scale  # ä½¿ç”¨ä¼ å…¥çš„åæ ‡ç¼©æ”¾æ¯”ä¾‹
            )
            
            # è®°å½•ç©º frames
            if not restructured_frames:
                logger.warning("âš ï¸ æ•°æ®é‡æ„åç”Ÿæˆçš„å¸§æ•°ä¸º0")
                return {}
            
            return {
                "frames": restructured_frames,
                "total_frames": len(restructured_frames),
                "participant_count": len(participants),
                "frame_step": frame_step,
            }

        except Exception as e:
            logger.error(f"âŒ åœ¨è§£ææ•°æ®é›†æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
            return {}

# åˆ›å»ºä¸€ä¸ªå•ä¾‹ï¼Œæ–¹ä¾¿åœ¨å…¶ä»–åœ°æ–¹ç›´æ¥å¯¼å…¥ä½¿ç”¨
dataset_parser_service = DatasetParserService()
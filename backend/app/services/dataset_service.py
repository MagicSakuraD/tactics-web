# ğŸ”§ æ•°æ®é›†å¤„ç†æœåŠ¡ - æ•°æ®é›†è§£æå’Œç®¡ç†çš„æ ¸å¿ƒé€»è¾‘
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from concurrent.futures import ThreadPoolExecutor
import asyncio

from ..config import settings
from ..models import DatasetInfo, FileInfo, ParticipantInfo, TrajectoryData, DatasetType

# å°è¯•å¯¼å…¥ tactics2d
try:
    from tactics2d.dataset_parser import LevelXParser
    TACTICS2D_AVAILABLE = True
except ImportError as e:
    TACTICS2D_AVAILABLE = False
    logging.warning(f"Tactics2Dä¸å¯ç”¨: {e}")

logger = logging.getLogger(__name__)

class DatasetService:
    """æ•°æ®é›†æœåŠ¡ç±»"""
    
    def __init__(self):
        self.parsers: Dict[str, Any] = {}
        self.executor = ThreadPoolExecutor(max_workers=4)
        
    async def get_available_datasets(self) -> List[DatasetInfo]:
        """è·å–å¯ç”¨çš„æ•°æ®é›†åˆ—è¡¨"""
        datasets = []
        
        # æ£€æŸ¥ highD æ•°æ®é›†
        if settings.HIGHD_DATA_DIR.exists():
            file_count = len(list(settings.HIGHD_DATA_DIR.glob("*_tracks.csv")))
            total_size = sum(f.stat().st_size for f in settings.HIGHD_DATA_DIR.glob("*.csv"))
            
            datasets.append(DatasetInfo(
                id="highD",
                name="highD Dataset",
                type="LevelX",
                file_count=file_count,
                total_size=total_size,
                available=file_count > 0 and TACTICS2D_AVAILABLE
            ))
        
        return datasets
    
    async def get_dataset_files(self, dataset: DatasetType) -> List[FileInfo]:
        """è·å–æ•°æ®é›†ä¸­çš„æ–‡ä»¶åˆ—è¡¨"""
        if not TACTICS2D_AVAILABLE:
            raise ValueError("Tactics2Dä¸å¯ç”¨")
            
        if dataset == DatasetType.HIGHD:
            return await self._get_highd_files()
        else:
            raise ValueError(f"æš‚ä¸æ”¯æŒæ•°æ®é›†: {dataset}")
    
    async def _get_highd_files(self) -> List[FileInfo]:
        """è·å– highD æ•°æ®é›†æ–‡ä»¶åˆ—è¡¨"""
        files = []
        parser = self._get_parser("highD")
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
        loop = asyncio.get_event_loop()
        
        for file_path in settings.HIGHD_DATA_DIR.glob("*_tracks.csv"):
            try:
                file_id = int(file_path.stem.split("_")[0])
                
                # å¼‚æ­¥è·å–æ–‡ä»¶ä¿¡æ¯
                stamp_range = await loop.run_in_executor(
                    self.executor, 
                    parser.get_stamp_range, 
                    file_id, 
                    str(settings.HIGHD_DATA_DIR)
                )
                
                location_id = await loop.run_in_executor(
                    self.executor,
                    parser.get_location,
                    file_id,
                    str(settings.HIGHD_DATA_DIR)
                )
                
                files.append(FileInfo(
                    file_id=file_id,
                    name=file_path.name,
                    size=file_path.stat().st_size,
                    location_id=int(location_id),
                    duration_seconds=float((int(stamp_range[1]) - int(stamp_range[0])) / 1000.0)
                ))
                
            except Exception as e:
                logger.warning(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                continue
        
        return sorted(files, key=lambda x: x.file_id)
    
    async def parse_trajectory(self, 
                             dataset: DatasetType, 
                             file_id: int,
                             stamp_range: Optional[Tuple[int, int]] = None,
                             participant_ids: Optional[List[int]] = None) -> TrajectoryData:
        """è§£æè½¨è¿¹æ•°æ®"""
        if not TACTICS2D_AVAILABLE:
            raise ValueError("Tactics2Dä¸å¯ç”¨")
            
        parser = self._get_parser(dataset.value)
        data_folder = self._get_data_folder(dataset)
        
        loop = asyncio.get_event_loop()
        
        # å¼‚æ­¥è§£æè½¨è¿¹
        participants, actual_range = await loop.run_in_executor(
            self.executor,
            parser.parse_trajectory,
            file_id,
            str(data_folder),
            stamp_range,
            participant_ids
        )
        
        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        participant_list = []
        for pid, participant in participants.items():
            # å®‰å…¨åœ°è½¬æ¢å‚ä¸è€…ID
            safe_pid = int(pid.item()) if hasattr(pid, 'item') else int(pid)
            
            participant_list.append(ParticipantInfo(
                id=safe_pid,
                type=type(participant).__name__,
                active_time_range=(int(actual_range[0]), int(actual_range[1])),
                attributes={
                    "driven_mode": getattr(participant, 'driven_mode', None),
                    "color": getattr(participant, 'color', None)
                }
            ))
        
        return TrajectoryData(
            file_id=file_id,
            dataset=dataset.value,
            timestamp_range=(int(actual_range[0]), int(actual_range[1])),
            participants=participant_list
        )
    
    def _get_parser(self, dataset: str):
        """è·å–è§£æå™¨å®ä¾‹"""
        if dataset not in self.parsers:
            if dataset == "highD":
                self.parsers[dataset] = LevelXParser("highD")
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {dataset}")
        
        return self.parsers[dataset]
    
    def _get_data_folder(self, dataset: DatasetType) -> Path:
        """è·å–æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„"""
        if dataset == DatasetType.HIGHD:
            return settings.HIGHD_DATA_DIR
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {dataset}")

# å…¨å±€æ•°æ®é›†æœåŠ¡å®ä¾‹
dataset_service = DatasetService()
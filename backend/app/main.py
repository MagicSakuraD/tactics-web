from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, UploadFile, File
from fastapi.responses import JSONResponse
import os
import shutil
import time
import logging
from pathlib import Path
from pydantic import BaseModel
from typing import Optional
from fastapi.middleware.cors import CORSMiddleware

# å¯¼å…¥WebSocketç›¸å…³æœåŠ¡
from app.api.websocket import router as websocket_router
from app.config import settings

# å¯¼å…¥åœ°å›¾ç›¸å…³çš„å·¥å…·
from app.utils.tactics2d_wrapper import tactics2d_wrapper
from app.utils.simple_formatter import data_formatter

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# ğŸš€ åº”ç”¨å…¥å£ç‚¹
# å¯¼å…¥tactics2d
try:
    from tactics2d.dataset_parser import LevelXParser
    TACTICS2D_AVAILABLE = True
except ImportError as e:
    TACTICS2D_AVAILABLE = False
    IMPORT_ERROR = str(e)

app = FastAPI(
    title="Tactics2D Test API",
    description="æµ‹è¯•tactics2d.dataset_parser.LevelXParser",
    version="0.1.0"
)

# æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„
DATA_FOLDER = Path(__file__).parent.parent / "data" / "LevelX" / "highD" / "data"

# æ·»åŠ CORSä¸­é—´ä»¶æ”¯æŒå‰ç«¯è°ƒç”¨
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # Next.jsé»˜è®¤ç«¯å£
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†ŒWebSocketè·¯ç”±
app.include_router(websocket_router)

# ç®€åŒ–çš„æ•°æ®æ¨¡å‹ - MVPç‰ˆæœ¬
class OSMUploadResponse(BaseModel):
    success: bool
    message: str
    file_path: Optional[str] = None
    file_size: Optional[int] = None

# æ•°æ®é›†åˆå§‹åŒ–è¯·æ±‚æ¨¡å‹
class DatasetInitRequest(BaseModel):
    dataset: str  # æ•°æ®é›†ç±»å‹
    file_id: int  # æ–‡ä»¶ID 
    dataset_path: str  # æ•°æ®é›†è·¯å¾„
    map_path: str  # OSMåœ°å›¾æ–‡ä»¶è·¯å¾„
    stamp_start: Optional[int] = None  # èµ·å§‹æ—¶é—´æˆ³
    stamp_end: Optional[int] = None  # ç»“æŸæ—¶é—´æˆ³
    perception_range: int = 50  # æ„ŸçŸ¥èŒƒå›´
    frame_step: int = 40  # å¸§æ­¥é•¿
    max_duration_ms: Optional[int] = None  # æœ€å¤§æŒç»­æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰

# æ•°æ®é›†åˆå§‹åŒ–å“åº”æ¨¡å‹
class DatasetInitResponse(BaseModel):
    success: bool
    message: str
    config: Optional[dict] = None
    error: Optional[str] = None

# å…¨å±€å˜é‡å­˜å‚¨å½“å‰åœ°å›¾çŠ¶æ€
current_map = {
    "file_path": None,
    "parsed_data": None,
    "uploaded_at": None
}

@app.get("/")
async def root():
    return {
        "message": "Tactics2D Test API", 
        "tactics2d_available": TACTICS2D_AVAILABLE,
        "data_folder": str(DATA_FOLDER),
        "data_folder_exists": DATA_FOLDER.exists()
    }

@app.get("/check-tactics2d")
async def check_tactics2d():
    """æ£€æŸ¥tactics2dæ˜¯å¦å¯ç”¨"""
    if not TACTICS2D_AVAILABLE:
        return {
            "available": False,
            "error": IMPORT_ERROR,
            "suggestion": "è¯·è¿è¡Œ: pip install tactics2d"
        }
    
    return {
        "available": True,
        "parser_class": str(LevelXParser),
        "message": "tactics2d.dataset_parser.LevelXParser å¯ç”¨"
    }

@app.get("/list-data-files")
async def list_data_files():
    """åˆ—å‡ºå¯ç”¨çš„æ•°æ®æ–‡ä»¶"""
    if not DATA_FOLDER.exists():
        raise HTTPException(status_code=404, detail=f"æ•°æ®æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {DATA_FOLDER}")
    
    files = []
    for file in DATA_FOLDER.glob("*.csv"):
        files.append({
            "name": file.name,
            "size": file.stat().st_size,
            "type": "tracks" if "tracks" in file.name else "meta"
        })
    
    return {
        "data_folder": str(DATA_FOLDER),
        "total_files": len(files),
        "files": sorted(files, key=lambda x: x["name"])
    }

@app.get("/test-parser/{file_id}")
async def test_parser(file_id: int):
    """æµ‹è¯•LevelXParserè§£ææŒ‡å®šæ–‡ä»¶çš„åŸºæœ¬åŠŸèƒ½"""
    if not TACTICS2D_AVAILABLE:
        raise HTTPException(status_code=500, detail="tactics2dä¸å¯ç”¨")
    
    if not DATA_FOLDER.exists():
        raise HTTPException(status_code=404, detail=f"æ•°æ®æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {DATA_FOLDER}")
    
    try:
        # åˆå§‹åŒ–è§£æå™¨
        parser = LevelXParser("highD")
        
        # è·å–æ—¶é—´èŒƒå›´ - ç¡®ä¿è½¬æ¢ä¸º Python int
        stamp_range = parser.get_stamp_range(file_id, str(DATA_FOLDER))
        stamp_range = (int(stamp_range[0]), int(stamp_range[1]))  # è½¬æ¢ numpy.int64 -> int
        
        # è·å–ä½ç½®ä¿¡æ¯ - ç¡®ä¿è½¬æ¢ä¸º Python int
        location_id = parser.get_location(file_id, str(DATA_FOLDER))
        location_id = int(location_id)  # è½¬æ¢ numpy.int64 -> int
        
        # è§£æè½¨è¿¹æ•°æ®ï¼ˆåªè§£æå¾ˆçŸ­çš„æ—¶é—´æ®µæ¥æµ‹è¯•ï¼‰
        test_duration = 200  # 200æ¯«ç§’
        test_stamp_range = (stamp_range[0], min(stamp_range[0] + test_duration, stamp_range[1]))
        
        participants, actual_range = parser.parse_trajectory(
            file_id, 
            str(DATA_FOLDER), 
            stamp_range=test_stamp_range
        )
        
        # ç¡®ä¿ actual_range ä¹Ÿæ˜¯ Python int
        actual_range = (int(actual_range[0]), int(actual_range[1]))
        
        # åˆ†æparticipantsæ•°æ®ç»“æ„
        participant_count = len(participants)
        participant_info = {}
        
        if participants:
            # è·å–ç¬¬ä¸€ä¸ªå‚ä¸è€…çš„è¯¦ç»†ä¿¡æ¯
            first_key = list(participants.keys())[0]
            # ç¡®ä¿ key æ˜¯ JSON å¯åºåˆ—åŒ–çš„
            if hasattr(first_key, 'item'):  # å¦‚æœæ˜¯ numpy ç±»å‹
                first_key = first_key.item()
            else:
                first_key = int(first_key)
                
            first_participant = participants[list(participants.keys())[0]]
            
            # å®‰å…¨åœ°è·å–å±æ€§ä¿¡æ¯ï¼Œé¿å…åºåˆ—åŒ–é—®é¢˜
            safe_attributes = []
            for attr in dir(first_participant):
                if not attr.startswith('_') and len(safe_attributes) < 15:  # é™åˆ¶æ•°é‡
                    try:
                        value = getattr(first_participant, attr)
                        # åªè®°å½•ç®€å•ç±»å‹çš„å±æ€§ï¼Œå¹¶ç¡®ä¿ç±»å‹å®‰å…¨
                        if isinstance(value, (int, float, str, bool)):
                            safe_attributes.append({
                                "name": attr,
                                "type": str(type(value).__name__),
                                "value": str(value)[:100]  # é™åˆ¶é•¿åº¦
                            })
                        elif isinstance(value, (list, tuple)):
                            safe_attributes.append({
                                "name": attr,
                                "type": str(type(value).__name__),
                                "value": f"length_{len(value)}"
                            })
                        else:
                            safe_attributes.append({
                                "name": attr,
                                "type": str(type(value).__name__),
                                "value": "complex_object"
                            })
                    except Exception:
                        safe_attributes.append({
                            "name": attr,
                            "type": "unknown",
                            "value": "access_error"
                        })
            
            participant_info = {
                "sample_participant_id": first_key,
                "participant_type": type(first_participant).__name__,
                "total_attributes": len(safe_attributes),
                "attributes": safe_attributes,
                "str_representation": str(first_participant)[:300] + "..." if len(str(first_participant)) > 300 else str(first_participant)
            }
        
        # ç¡®ä¿æ‰€æœ‰participant IDséƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„
        participant_ids_safe = []
        for pid in list(participants.keys())[:10]:
            if hasattr(pid, 'item'):  # numpyç±»å‹
                participant_ids_safe.append(pid.item())
            else:
                participant_ids_safe.append(int(pid))
        
        return {
            "success": True,
            "file_id": file_id,
            "parser_dataset": "highD",
            "location_id": location_id,
            "timestamp_info": {
                "full_range_ms": stamp_range,
                "full_duration_ms": stamp_range[1] - stamp_range[0],
                "test_range_ms": test_stamp_range,
                "actual_parsed_range_ms": actual_range
            },
            "participant_analysis": {
                "total_participants": participant_count,
                "participant_ids": participant_ids_safe,
                "sample_participant": participant_info
            }
        }
        
    except Exception as e:
        # è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼Œå¸®åŠ©è°ƒè¯•
        import traceback
        return {
            "success": False,
            "error": {
                "message": str(e),
                "type": type(e).__name__,
                "traceback": traceback.format_exc()[-1000:]  # æœ€å1000å­—ç¬¦
            },
            "test_context": {
                "file_id": file_id,
                "data_folder": str(DATA_FOLDER),
                "tactics2d_available": TACTICS2D_AVAILABLE
            }
        }

@app.get("/test-all-files")
async def test_all_files():
    """æµ‹è¯•å¤šä¸ªæ•°æ®æ–‡ä»¶çš„åŸºæœ¬ä¿¡æ¯ï¼ˆä¸è¿›è¡Œå®Œæ•´è§£æï¼‰"""
    if not TACTICS2D_AVAILABLE:
        raise HTTPException(status_code=500, detail="tactics2dä¸å¯ç”¨")
    
    if not DATA_FOLDER.exists():
        raise HTTPException(status_code=404, detail=f"æ•°æ®æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {DATA_FOLDER}")
    
    # æŸ¥æ‰¾æ‰€æœ‰tracksæ–‡ä»¶
    track_files = []
    for file in DATA_FOLDER.glob("*_tracks.csv"):
        try:
            file_id = int(file.name.split("_")[0])
            track_files.append(file_id)
        except ValueError:
            continue
    
    results = []
    # åªæµ‹è¯•å‰3ä¸ªæ–‡ä»¶ï¼Œé¿å…é•¿æ—¶é—´ç­‰å¾…
    for file_id in sorted(track_files)[:3]:
        try:
            parser = LevelXParser("highD")
            
            # åªè·å–åŸºæœ¬ä¿¡æ¯ï¼Œä¸è§£æè½¨è¿¹æ•°æ®
            stamp_range = parser.get_stamp_range(file_id, str(DATA_FOLDER))
            location_id = parser.get_location(file_id, str(DATA_FOLDER))
            
            # ç¡®ä¿ç±»å‹å®‰å…¨
            stamp_range = (int(stamp_range[0]), int(stamp_range[1]))
            location_id = int(location_id)
            
            results.append({
                "file_id": file_id,
                "location_id": location_id,
                "timestamp_range": stamp_range,
                "duration_seconds": float((stamp_range[1] - stamp_range[0]) / 1000.0),
                "success": True,
                "error": None
            })
            
        except Exception as e:
            results.append({
                "file_id": file_id,
                "location_id": None,
                "timestamp_range": None,
                "duration_seconds": None,
                "success": False,
                "error": str(e)
            })
    
    return {
        "summary": {
            "total_files_found": len(track_files),
            "files_tested": len(results),
            "successful_tests": len([r for r in results if r["success"]]),
            "failed_tests": len([r for r in results if not r["success"]])
        },
        "available_file_ids": sorted(track_files),
        "test_results": results
    }

# æ–°å¢ï¼šç®€å•æµ‹è¯•æ¥å£ï¼Œåªæ£€æŸ¥åŸºæœ¬åŠŸèƒ½
@app.get("/quick-test")
async def quick_test():
    """å¿«é€Ÿæµ‹è¯•LevelXParseråŸºæœ¬åŠŸèƒ½"""
    if not TACTICS2D_AVAILABLE:
        return {"error": "tactics2dæœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥"}
    
    try:
        # æµ‹è¯•è§£æå™¨åˆå§‹åŒ–
        parser = LevelXParser("highD")
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶å¤¹
        if not DATA_FOLDER.exists():
            return {
                "parser_init": "success",
                "data_folder": "missing",
                "message": f"æ•°æ®æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {DATA_FOLDER}"
            }
        
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ–‡ä»¶
        first_file = list(DATA_FOLDER.glob("01_tracks.csv"))
        if not first_file:
            return {
                "parser_init": "success", 
                "data_folder": "exists",
                "first_file": "missing",
                "message": "æ‰¾ä¸åˆ°01_tracks.csvæ–‡ä»¶"
            }
        
        # å°è¯•è·å–åŸºæœ¬ä¿¡æ¯
        stamp_range = parser.get_stamp_range(1, str(DATA_FOLDER))
        location_id = parser.get_location(1, str(DATA_FOLDER))
        
        # ç¡®ä¿ç±»å‹å®‰å…¨ - è½¬æ¢ numpy ç±»å‹ä¸º Python åŸç”Ÿç±»å‹
        stamp_range = (int(stamp_range[0]), int(stamp_range[1]))
        location_id = int(location_id)
        
        return {
            "parser_init": "success",
            "data_folder": "exists", 
            "first_file": "exists",
            "basic_parsing": "success",
            "sample_data": {
                "location_id": location_id,
                "timestamp_range": stamp_range,
                "duration_seconds": float((stamp_range[1] - stamp_range[0]) / 1000.0)
            }
        }
        
    except Exception as e:
        return {
            "parser_init": "unknown",
            "error": str(e),
            "error_type": type(e).__name__
        }

# ğŸš€ MVPåŠŸèƒ½ï¼šOSMæ–‡ä»¶ä¸Šä¼ å’Œè§£æ
@app.post("/api/upload-osm")
async def upload_osm_file(file: UploadFile = File(...)):
    """ä¸Šä¼ OSMæ–‡ä»¶ - MVPæ ¸å¿ƒåŠŸèƒ½"""
    try:
        # éªŒè¯æ–‡ä»¶ç±»å‹
        if not file.filename.endswith('.osm'):
            return OSMUploadResponse(
                success=False,
                message="åªæ”¯æŒ.osmæ ¼å¼çš„æ–‡ä»¶"
            )
        
        # åˆ›å»ºä¸Šä¼ ç›®å½•
        upload_dir = Path("/home/quinn/APP/Code/tactics2d-web/backend/data/uploaded_maps")
        upload_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æ–‡ä»¶
        file_path = upload_dir / file.filename
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        file_size = file_path.stat().st_size
        
        # æ›´æ–°å…¨å±€åœ°å›¾çŠ¶æ€
        from datetime import datetime
        current_map.update({
            "file_path": str(file_path),
            "parsed_data": None,  # å°†åœ¨WebSocketä¸­è§£æ
            "uploaded_at": datetime.now().isoformat()
        })
        
        print(f"ğŸ—ºï¸ [UPLOAD] OSMæ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_path}")
        print(f"ğŸ“Š [UPLOAD] æ–‡ä»¶å¤§å°: {file_size} bytes")
        
        return OSMUploadResponse(
            success=True,
            message=f"OSMæ–‡ä»¶ '{file.filename}' ä¸Šä¼ æˆåŠŸ",
            file_path=str(file_path),
            file_size=file_size
        )
        
    except Exception as e:
        print(f"âŒ [UPLOAD] æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
        return OSMUploadResponse(
            success=False,
            message=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}"
        )

@app.get("/api/current-map")
async def get_current_map():
    """è·å–å½“å‰åœ°å›¾çŠ¶æ€"""
    if current_map["file_path"]:
        return {
            "success": True,
            "has_map": True,
            "file_path": current_map["file_path"],
            "uploaded_at": current_map["uploaded_at"],
            "parsed": current_map["parsed_data"] is not None
        }
    else:
        return {
            "success": True,
            "has_map": False,
            "message": "æœªä¸Šä¼ åœ°å›¾æ–‡ä»¶"
        }

@app.get("/api/map")
async def get_map_data():
    """HTTP API: è·å–åœ°å›¾æ•°æ® - ä½¿ç”¨çœŸå®OSMè§£ææˆ–æ¨¡æ‹Ÿæ•°æ®"""
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰å·²ä¸Šä¼ çš„åœ°å›¾
        if current_map["file_path"] and Path(current_map["file_path"]).exists():
            print(f"ğŸ—ºï¸  [HTTP] ä½¿ç”¨çœŸå®OSMåœ°å›¾: {current_map['file_path']}")
            
            # å¦‚æœå·²ç»è§£æè¿‡ï¼Œç›´æ¥è¿”å›ç¼“å­˜æ•°æ®
            if current_map["parsed_data"]:
                map_data = data_formatter.format_map_data(current_map["parsed_data"])
                print(f"ğŸ“¤ [HTTP] è¿”å›ç¼“å­˜çš„åœ°å›¾æ•°æ®")
                return {
                    "success": True,
                    "source": "cached_osm",
                    "data": map_data,
                    "file_path": current_map["file_path"]
                }
            
            # å°è¯•è§£æOSMåœ°å›¾
            try:
                print(f"ğŸ”„ [HTTP] å¼€å§‹è§£æOSMåœ°å›¾")
                map_info = tactics2d_wrapper.parse_osm_map_simple(current_map["file_path"])
                current_map["parsed_data"] = map_info
                
                map_data = data_formatter.format_map_data(map_info)
                
                print(f"âœ… [HTTP] OSMåœ°å›¾è§£ææˆåŠŸ:")
                print(f"   - roads: {len(map_data.get('roads', []))}")
                print(f"   - lanes: {len(map_data.get('lanes', []))}")
                print(f"   - boundaries: {len(map_data.get('boundaries', []))}")
                
                return {
                    "success": True,
                    "source": "real_osm",
                    "data": map_data,
                    "file_path": current_map["file_path"],
                    "metadata": {
                        "roads_count": len(map_data.get('roads', [])),
                        "lanes_count": len(map_data.get('lanes', [])),
                        "boundaries_count": len(map_data.get('boundaries', []))
                    }
                }
                
            except Exception as osm_error:
                print(f"âŒ [HTTP] OSMåœ°å›¾è§£æå¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®: {osm_error}")
                # è§£æå¤±è´¥æ—¶å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®
        
        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆæ²¡æœ‰åœ°å›¾æ–‡ä»¶æˆ–è§£æå¤±è´¥æ—¶ï¼‰
        print(f"ğŸ—ºï¸  [HTTP] ä½¿ç”¨æ¨¡æ‹Ÿåœ°å›¾æ•°æ®è¿›è¡Œæµ‹è¯•")
        
        mock_map_info = {
            "roads": [
                {
                    "id": "highway_main",
                    "coordinates": [[0, 0], [100, 0], [200, 5], [300, 0]],
                    "width": 12.0
                }
            ],
            "lanes": [
                {
                    "id": "lane_1",
                    "coordinates": [[0, -3], [100, -3], [200, 2], [300, -3]],
                    "width": 3.5,
                    "subtype": "solid"
                },
                {
                    "id": "lane_2", 
                    "coordinates": [[0, 3], [100, 3], [200, 8], [300, 3]],
                    "width": 3.5,
                    "subtype": "dashed"
                }
            ],
            "boundaries": [
                {
                    "id": "left_boundary",
                    "coordinates": [[0, -6], [100, -6], [200, -1], [300, -6]]
                },
                {
                    "id": "right_boundary", 
                    "coordinates": [[0, 6], [100, 6], [200, 11], [300, 6]]
                }
            ]
        }
        
        map_data = data_formatter.format_map_data(mock_map_info)
        
        print(f"ğŸ“Š [HTTP] æ¨¡æ‹Ÿåœ°å›¾æ•°æ®ç»Ÿè®¡:")
        print(f"   - roads: {len(map_data.get('roads', []))}")
        print(f"   - lanes: {len(map_data.get('lanes', []))}")
        print(f"   - boundaries: {len(map_data.get('boundaries', []))}")
        print(f"ğŸ“¤ [HTTP] è¿”å›æ¨¡æ‹Ÿåœ°å›¾æ•°æ®")
        
        return {
            "success": True,
            "source": "mock_data",
            "data": map_data,
            "metadata": {
                "roads_count": len(map_data.get('roads', [])),
                "lanes_count": len(map_data.get('lanes', [])),
                "boundaries_count": len(map_data.get('boundaries', []))
            }
        }
            
    except Exception as e:
        print(f"âŒ [HTTP] åœ°å›¾æ•°æ®è·å–å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e),
            "source": "error"
        }

@app.post("/api/simulation/initialize")
async def initialize_simulation(request: DatasetInitRequest):
    """åˆå§‹åŒ–ä»¿çœŸæ•°æ®å¤„ç† - å¤„ç†å‰ç«¯è¡¨å•æäº¤çš„OSMå’Œæ•°æ®é›†é…ç½®"""
    try:
        print(f"ğŸš€ [INIT] æ”¶åˆ°ä»¿çœŸåˆå§‹åŒ–è¯·æ±‚")
        print(f"   - æ•°æ®é›†ç±»å‹: {request.dataset}")
        print(f"   - æ–‡ä»¶ID: {request.file_id}")
        print(f"   - æ•°æ®é›†è·¯å¾„: {request.dataset_path}")
        print(f"   - åœ°å›¾æ–‡ä»¶è·¯å¾„: {request.map_path}")
        print(f"   - æ„ŸçŸ¥èŒƒå›´: {request.perception_range}m")
        print(f"   - å¸§æ­¥é•¿: {request.frame_step}")
        
        # éªŒè¯OSMåœ°å›¾æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(request.map_path).exists():
            print(f"âŒ [INIT] OSMåœ°å›¾æ–‡ä»¶ä¸å­˜åœ¨: {request.map_path}")
            return DatasetInitResponse(
                success=False,
                message=f"OSMåœ°å›¾æ–‡ä»¶ä¸å­˜åœ¨: {request.map_path}",
                error="file_not_found"
            )
        
        # éªŒè¯æ•°æ®é›†è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not Path(request.dataset_path).exists():
            print(f"âŒ [INIT] æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {request.dataset_path}")
            return DatasetInitResponse(
                success=False,
                message=f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {request.dataset_path}",
                error="dataset_path_not_found"
            )
        
        # æ›´æ–°å…¨å±€åœ°å›¾çŠ¶æ€
        current_map["file_path"] = request.map_path
        current_map["uploaded_at"] = "now"
        current_map["parsed_data"] = None  # æ ‡è®°éœ€è¦é‡æ–°è§£æ
        
        # éªŒè¯Tactics2Dæ˜¯å¦å¯ç”¨
        if not tactics2d_wrapper.is_available():
            print(f"âš ï¸  [INIT] Tactics2Dä¸å¯ç”¨ï¼Œä»…èƒ½æä¾›åŸºç¡€åŠŸèƒ½")
            return DatasetInitResponse(
                success=True,
                message="é…ç½®å·²ä¿å­˜ï¼Œä½†Tactics2Dä¸å¯ç”¨ï¼Œä»…æä¾›åŸºç¡€å¯è§†åŒ–åŠŸèƒ½",
                config={
                    "dataset": request.dataset,
                    "file_id": request.file_id,
                    "map_path": request.map_path,
                    "dataset_path": request.dataset_path,
                    "tactics2d_available": False
                }
            )
        
        # å°è¯•è§£æOSMåœ°å›¾
        try:
            print(f"ğŸ—ºï¸  [INIT] å¼€å§‹è§£æOSMåœ°å›¾: {request.map_path}")
            map_info = tactics2d_wrapper.parse_osm_map_simple(request.map_path)
            current_map["parsed_data"] = map_info
            
            print(f"âœ… [INIT] OSMåœ°å›¾è§£ææˆåŠŸ:")
            print(f"   - é“è·¯æ•°é‡: {len(map_info.get('roads', []))}")
            print(f"   - è½¦é“æ•°é‡: {len(map_info.get('lanes', []))}")
            print(f"   - è¾¹ç•Œæ•°é‡: {len(map_info.get('boundaries', []))}")
            
        except Exception as e:
            print(f"âŒ [INIT] OSMåœ°å›¾è§£æå¤±è´¥: {e}")
            return DatasetInitResponse(
                success=False,
                message=f"OSMåœ°å›¾è§£æå¤±è´¥: {str(e)}",
                error="osm_parse_error"
            )
        
        # å°è¯•åˆå§‹åŒ–æ•°æ®é›†è§£æå™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            from tactics2d.dataset_parser import LevelXParser
            parser = LevelXParser(request.dataset)
            
            # éªŒè¯æ–‡ä»¶IDæ˜¯å¦æœ‰æ•ˆ
            stamp_range = parser.get_stamp_range(request.file_id, request.dataset_path)
            print(f"ğŸ“Š [INIT] æ•°æ®é›†éªŒè¯æˆåŠŸ:")
            print(f"   - æ—¶é—´æˆ³èŒƒå›´: {stamp_range}")
            
        except Exception as e:
            print(f"âš ï¸  [INIT] æ•°æ®é›†è§£æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            # ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºåœ°å›¾å·²ç»æˆåŠŸè§£æ
        
        # æˆåŠŸå“åº”
        success_config = {
            "dataset": request.dataset,
            "file_id": request.file_id,
            "map_path": request.map_path,
            "dataset_path": request.dataset_path,
            "perception_range": request.perception_range,
            "frame_step": request.frame_step,
            "stamp_start": request.stamp_start,
            "stamp_end": request.stamp_end,
            "tactics2d_available": True,
            "map_parsed": True
        }
        
        print(f"âœ… [INIT] ä»¿çœŸåˆå§‹åŒ–å®Œæˆ")
        
        return DatasetInitResponse(
            success=True,
            message="æ•°æ®é›†å’Œåœ°å›¾é…ç½®æˆåŠŸï¼Œå¯ä»¥å¼€å§‹å¯è§†åŒ–",
            config=success_config
        )
        
    except Exception as e:
        print(f"âŒ [INIT] ä»¿çœŸåˆå§‹åŒ–å¤±è´¥: {e}")
        return DatasetInitResponse(
            success=False,
            message=f"ä»¿çœŸåˆå§‹åŒ–å¤±è´¥: {str(e)}",
            error="initialization_error"
        )

@app.post("/api/dataset/parse")
async def parse_dataset(request: DatasetInitRequest):
    """è§£ææ•°æ®é›†å¹¶åˆ›å»ºä»¿çœŸä¼šè¯"""
    try:
        logger.info(f"ğŸš€ å¼€å§‹è§£ææ•°æ®é›†: {request.dataset}, æ–‡ä»¶ID: {request.file_id}")
        
        # éªŒè¯æ•°æ®é›†è·¯å¾„
        if not Path(request.dataset_path).exists():
            raise HTTPException(
                status_code=404, 
                detail=f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {request.dataset_path}"
            )
        
        # éªŒè¯Tactics2Då¯ç”¨æ€§
        if not tactics2d_wrapper.is_available():
            raise HTTPException(
                status_code=500,
                detail="Tactics2Dåº“ä¸å¯ç”¨ï¼Œæ— æ³•è§£ææ•°æ®é›†"
            )
        
        # è®¾ç½®è§£æå‚æ•°
        max_duration_ms = getattr(request, 'max_duration_ms', 5000)  # é»˜è®¤5ç§’
        
        # è§£ææ•°æ®é›†
        session_data = tactics2d_wrapper.parse_dataset_for_session(
            dataset=request.dataset,
            file_id=request.file_id,
            data_folder=request.dataset_path,
            max_duration_ms=max_duration_ms
        )
        
        # ç”Ÿæˆä¼šè¯ID
        session_id = f"session_{request.dataset}_{request.file_id}_{int(time.time())}"
        
        # æ„å»ºå“åº”æ•°æ®
        response_data = {
            "session_id": session_id,
            "dataset": request.dataset,
            "file_id": request.file_id,
            "total_frames": session_data["session_data"]["total_frames"],
            "participant_count": session_data["session_data"]["participant_count"],
            "duration_seconds": session_data["session_data"]["duration_seconds"],
            "timestamp_range": session_data["session_data"]["timestamp_range"],
            "participants": session_data["session_data"]["participants"],
            "status": "success",
            "message": f"æˆåŠŸè§£ææ•°æ®é›†ï¼Œå…±{session_data['session_data']['participant_count']}ä¸ªå‚ä¸è€…"
        }
        
        # å°†è½¨è¿¹æ•°æ®å­˜å‚¨åˆ°å…¨å±€çŠ¶æ€ï¼ˆå®é™…é¡¹ç›®ä¸­åº”è¯¥ç”¨æ•°æ®åº“æˆ–ç¼“å­˜ï¼‰
        # è¿™é‡Œç®€åŒ–å­˜å‚¨åˆ°å…¨å±€å˜é‡
        if not hasattr(app.state, 'sessions'):
            app.state.sessions = {}
        
        app.state.sessions[session_id] = {
            "session_data": session_data["session_data"],
            "trajectory_frames": session_data["trajectory_frames"],
            "created_at": time.time()
        }
        
        logger.info(f"âœ… æ•°æ®é›†è§£æå®Œæˆï¼Œä¼šè¯ID: {session_id}")
        return response_data
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®é›†è§£æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/session/{session_id}")
async def get_session_info(session_id: str):
    """è·å–ä¼šè¯ä¿¡æ¯"""
    if not hasattr(app.state, 'sessions') or session_id not in app.state.sessions:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
    
    session = app.state.sessions[session_id]
    return {
        "session_id": session_id,
        "session_data": session["session_data"],
        "created_at": session["created_at"],
        "frame_count": len(session["trajectory_frames"])
    }

@app.get("/api/session/{session_id}/frame/{frame_number}")
async def get_session_frame(session_id: str, frame_number: int):
    """è·å–ä¼šè¯çš„æŒ‡å®šå¸§æ•°æ®"""
    if not hasattr(app.state, 'sessions') or session_id not in app.state.sessions:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
    
    session = app.state.sessions[session_id]
    frame_key = str(frame_number)
    
    if frame_key not in session["trajectory_frames"]:
        raise HTTPException(status_code=404, detail=f"å¸§ {frame_number} ä¸å­˜åœ¨")
    
    return session["trajectory_frames"][frame_key]